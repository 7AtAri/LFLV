{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade transformers datasets\n",
    "#!pip install --upgrade huggingface hub\n",
    "#!pip install --upgrade pip\n",
    "#!pip install --upgrade torch torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, Dinov2Model\n",
    "import torch, torchvision\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "0.16.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available()  \n",
    "                            else \"mps\"  if torch.backends.mps.is_available() \n",
    "                            else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# If you have a model, move it to the device\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/ari/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "#!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ari/Documents/Data_Science/3_semester/learning_from_las_vegas/LFLV/LasVegas/lib/python3.11/site-packages/datasets/load.py:1429: FutureWarning: The repository for huggingface/cats-image contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/huggingface/cats-image\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 2.56k/2.56k [00:00<00:00, 8.21MB/s]\n",
      "Downloading data: 100%|██████████| 173k/173k [00:00<00:00, 804kB/s] \n",
      "Generating test split: 1 examples [00:00,  2.24 examples/s]\n",
      "preprocessor_config.json: 100%|██████████| 436/436 [00:00<00:00, 2.73MB/s]\n",
      "config.json: 100%|██████████| 548/548 [00:00<00:00, 1.66MB/s]\n",
      "model.safetensors: 100%|██████████| 346M/346M [00:28<00:00, 11.9MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 257, 768]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-base\")\n",
    "model = Dinov2Model.from_pretrained(\"facebook/dinov2-base\")\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "list(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### last hidden state shape\n",
    "\n",
    "* 1 -> input batch size\n",
    "* 257 -> 256 image patches the input images are split into (one additional token for a special purpose, like classification or a start/end token). \n",
    "* 768 -> This is the dimensionality of the embeddings. Each of the 257 elements (patches or tokens) is transformed into a 768-dimensional vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1747, -0.4729,  1.0936,  ...,  0.2041,  1.1101,  0.1363],\n",
       "         [-3.2780, -0.8269, -0.9210,  ...,  1.4415, -0.5364, -0.8757],\n",
       "         [-2.9129,  1.1284, -0.7306,  ...,  0.6959, -1.8791, -2.3638],\n",
       "         ...,\n",
       "         [-0.5463,  1.4382, -0.2563,  ...,  0.1873, -2.9950,  0.4067],\n",
       "         [-3.0848,  2.0568,  1.5137,  ...,  0.9157, -2.7059,  2.2017],\n",
       "         [-0.7499,  0.0903,  1.3731,  ..., -0.2961, -2.3682, -0.1329]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LasVegas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
